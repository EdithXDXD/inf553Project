{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession.builder.appName(\"item similarity\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()\n",
    "\n",
    "user_raw_data = spark.read.json(\"/Users/elgin/Downloads/INF553/yelp_dataset/yelp_academic_dataset_user.json\").select(\"user_id\", \"review_count\")\n",
    "review_raw_data = spark.read.json(\"/Users/elgin/Downloads/INF553/yelp_dataset/yelp_academic_dataset_review.json\").select(\"user_id\", \"business_id\", \"stars\")\n",
    "business_raw_data_count = spark.read.json(\"/Users/elgin/Downloads/INF553/yelp_dataset/yelp_academic_dataset_business.json\").select(\"business_id\", \"review_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate business similarity and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "def ItemSimilarity(x, y):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        x : restaurant1 id\n",
    "        y : restaurant2 id\n",
    "    Output:\n",
    "        similarity : similarity between x and y\n",
    "    \"\"\"\n",
    "    #extract all reviews whose business_id equals x and y\n",
    "    x_reviews_panda = review_bus_panda.loc[review_bus_panda['business_id'] == x]\n",
    "    y_reviews_panda = review_bus_panda.loc[review_bus_panda['business_id'] == y]\n",
    "    \n",
    "    #calculate square_sum of x and y\n",
    "    square_sum_x = 0.0\n",
    "    x_userid_set = set()\n",
    "    x_userid_rating_dic = {}\n",
    "    for index, row in x_reviews_panda.iterrows():\n",
    "        square_sum_x = square_sum_x + pow(row[\"stars\"], 2)\n",
    "        x_userid_set.add(row[\"user_id\"])\n",
    "        x_userid_rating_dic[row[\"user_id\"]] = row[\"stars\"]\n",
    "    square_sum_x = math.sqrt(square_sum_x)\n",
    "    \n",
    "    square_sum_y = 0.0\n",
    "    y_userid_set = set()\n",
    "    y_userid_rating_dic = {}\n",
    "    for index, row in y_reviews_panda.iterrows():\n",
    "        square_sum_y = square_sum_y + pow(row[\"stars\"], 2)\n",
    "        y_userid_set.add(row[\"user_id\"])\n",
    "        y_userid_rating_dic[row[\"user_id\"]] = row[\"stars\"]\n",
    "    square_sum_y = math.sqrt(square_sum_y)\n",
    "    \n",
    "    #check if square_sum equals 0\n",
    "    if square_sum_x * square_sum_y == 0:\n",
    "        return 0\n",
    "    \n",
    "    #calculate product of ratings of items rated both by x and y\n",
    "    product_sum = 0.0\n",
    "    common_userid = x_userid_set & y_userid_set\n",
    "    for user in common_userid:\n",
    "        product_sum = product_sum + (x_userid_rating_dic[user])*(y_userid_rating_dic[user])\n",
    "    similarity = product_sum / (square_sum_x * square_sum_y)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def Prediction(business_id, user_id):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        candidate_set: a set of business_id that the user might try\n",
    "    Output:\n",
    "        prediction_list: a list of prediction(format: [candidate_business_id, prediction])\n",
    "    \"\"\"\n",
    "    \n",
    "    #extract business_id the user rated\n",
    "    businessid_rating_dic = {}\n",
    "    business_id_rated = []\n",
    "    \n",
    "    number_review_to_use = 20\n",
    "    review_user_rated = review_bus_panda.loc[review_bus_panda['user_id'] == user_id].sort_values(by = ['breview_count'], ascending = 0)\n",
    "    review_few_rating = review_user_rated.loc[review_user_rated['stars'] < 2]\n",
    "    review_medium_rating = review_user_rated.loc[(review_user_rated['stars'] >= 2) & (review_user_rated['stars'] < 4)]\n",
    "    review_high_rating = review_user_rated.loc[review_user_rated['stars'] >= 4]\n",
    "    \n",
    "    count_reviews = len(review_user_rated.index)\n",
    "    num_few_raintg = math.ceil((len(review_few_rating.index) / count_reviews) * number_review_to_use)\n",
    "    num_medium_rating = math.ceil((len(review_medium_rating.index) / count_reviews) * number_review_to_use)\n",
    "    num_high_rating = number_review_to_use - num_few_raintg - num_medium_rating\n",
    "    \n",
    "    df_few = review_few_rating.head(num_few_raintg)\n",
    "    df_medium = review_medium_rating.head(num_medium_rating)\n",
    "    df_high = review_high_rating.head(num_high_rating)\n",
    "    review_processed = pd.concat([df_few, df_medium, df_high], axis=0, ignore_index=True)\n",
    "    \n",
    "    for index, row in review_processed.iterrows():\n",
    "        b_id = row[\"business_id\"]\n",
    "        rating = row[\"stars\"]\n",
    "        businessid_rating_dic[b_id] = rating\n",
    "        business_id_rated.append(b_id)\n",
    "    \n",
    "    #calculate prediction\n",
    "    prediction = 0.0\n",
    "    sim_sum = 0.0\n",
    "    for b in business_id_rated:\n",
    "        sim = ItemSimilarity(business_id, b)\n",
    "        rating = (businessid_rating_dic[b]) * sim\n",
    "        prediction = prediction + rating\n",
    "        sim_sum = sim_sum + sim\n",
    "#         print(sim,businessid_rating_dic[b],rating)\n",
    "    if sim_sum == 0:\n",
    "        prediction = 0\n",
    "    else:\n",
    "        prediction = prediction / sim_sum  \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(fileName):\n",
    "    testData = []\n",
    "    with open(fileName) as txtData:\n",
    "        lines = txtData.readlines()\n",
    "        for line in lines:\n",
    "            lineData = line.strip().split(',')\n",
    "            testData.append(lineData)\n",
    "    return testData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadPred(prediction_file_name):\n",
    "    predData = []\n",
    "    with open(prediction_file_name) as txtData:\n",
    "        lines = txtData.readlines()\n",
    "        for line in lines:\n",
    "            lineData = line.strip().split(' ')\n",
    "            predData.append(lineData)\n",
    "    return predData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute accuracy and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalResult(test_file_name, pred_file_name):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_file_name: path of test file \n",
    "        pred_file_name: path of prediction file\n",
    "    Output:\n",
    "        [TP,FP,FN,TN,LN]: LN is len(test_data)\n",
    "    \"\"\"\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    \n",
    "    test_data = LoadData(test_file_name)\n",
    "    prediction_data = LoadPred(pred_file_name)\n",
    "    \n",
    "    for i in range(len(prediction_data)):\n",
    "        pred = float(prediction_data[i][2])\n",
    "        test = float(test_data[i][2])\n",
    "        if pred >= 4 and test >= 4:\n",
    "            TP = TP + 1\n",
    "        elif pred >= 4 and test < 4:\n",
    "            FP = FP + 1\n",
    "        elif pred < 4 and test >= 4:\n",
    "            FN = FN + 1\n",
    "    TN = len(prediction_data) - TP - FP - FN\n",
    "    LN = len(prediction_data)\n",
    "    return([TP,FP,FN,TN,LN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_user = review_raw_data.join(user_raw_data, on = \"user_id\", how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_user = review_user.filter(review_user[\"review_count\"] > 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_raw_data_count = business_raw_data_count.withColumnRenamed(\"review_count\", \"breview_count\")\n",
    "review_bus = review_user.join(business_raw_data_count, on = \"business_id\", how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_bus = review_bus.filter(review_bus['breview_count'] > 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_bus_panda = review_bus.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_avg_data = spark.read.json(\"/Users/elgin/Downloads/INF553/yelp_dataset/yelp_academic_dataset_user.json\").select(\"user_id\", \"average_stars\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_avg = spark.read.json(\"/Users/elgin/Downloads/INF553/yelp_dataset/yelp_academic_dataset_business.json\").select(\"business_id\", \"stars\", \"review_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_avgStars = business_avg.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = LoadData(\"/Users/elgin/Downloads/test_small_2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test data and generate output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QkO16gr4QaPaKPWeUTAEqA eDJ0aUIAzc6PNuZ_6ELR1g 4.999999999999999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-86d01abe8ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mres_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mres_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_s\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mipred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mipred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-42defff8f574>\u001b[0m in \u001b[0;36mPrediction\u001b[0;34m(business_id, user_id)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0msim_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbusiness_id_rated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mItemSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbusiness_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbusinessid_rating_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-42defff8f574>\u001b[0m in \u001b[0;36mItemSimilarity\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#extract all reviews whose business_id equals x and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_reviews_panda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_bus_panda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview_bus_panda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0my_reviews_panda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_bus_panda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview_bus_panda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#calculate square_sum of x and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text_file = open(\"projectOutput1.txt\", \"w\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for item in test_data:\n",
    "    res_s = \"\"\n",
    "    res_s = res_s + item[0] + \" \" + item[1] + \" \"\n",
    "    ipred = Prediction(item[1], item[0])\n",
    "    pred = str(ipred)\n",
    "    if ipred == 0:\n",
    "        busi = business_avgStars.loc[business_avgStars['business_id'] == item[1]]\n",
    "        pred = str(busi['stars'].values[0])\n",
    "    res_s = res_s + pred\n",
    "    print(res_s)\n",
    "    text_file.write(res_s + \"\\n\")\n",
    "text_file.close()\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuray, precision, recall and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_res_file = open(\"small_test_res.txt\", \"w\")\n",
    "small_test_res = CalResult(\"/Users/elgin/Downloads/test_small.txt\",\"/Users/elgin/Desktop/item_ouput/test_small_item_output.txt\")\n",
    "accuracy = (small_test_res[0]+small_test_res[3]) / small_test_res[4]\n",
    "precision = small_test_res[0] / (small_test_res[0]+small_test_res[1])\n",
    "recall = small_test_res[0] / (small_test_res[0]+small_test_res[2])\n",
    "small_test_res_file.write(\"accuracy : \"+str(accuracy)+\"\\n\")\n",
    "small_test_res_file.write(\"precision : \"+str(precision)+\"\\n\")\n",
    "small_test_res_file.write(\"recall : \"+str(recall))\n",
    "small_test_res_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_res_file = open(\"small_test2_res.txt\", \"w\")\n",
    "small_test_res = CalResult(\"/Users/elgin/Downloads/test_small_2.txt\",\"/Users/elgin/Desktop/item_ouput/test_small2_item_output.txt\")\n",
    "accuracy = (small_test_res[0]+small_test_res[3]) / small_test_res[4]\n",
    "precision = small_test_res[0] / (small_test_res[0]+small_test_res[1])\n",
    "recall = small_test_res[0] / (small_test_res[0]+small_test_res[2])\n",
    "small_test_res_file.write(\"accuracy : \"+str(accuracy)+\"\\n\")\n",
    "small_test_res_file.write(\"precision : \"+str(precision)+\"\\n\")\n",
    "small_test_res_file.write(\"recall : \"+str(recall))\n",
    "small_test_res_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8011191927817288\n"
     ]
    }
   ],
   "source": [
    "test_data_small = LoadData(\"/Users/elgin/Downloads/test_small.txt\") \n",
    "pred_data_small = LoadPred(\"/Users/elgin/Desktop/item_ouput/test_small_item_output.txt\")\n",
    "dif_square_sum = 0.0\n",
    "for i in range(len(test_data_small)):\n",
    "    test_rating = float(test_data_small[i][2])\n",
    "    pred_rating = float(pred_data_small[i][2])\n",
    "    dif = test_rating - pred_rating\n",
    "    dif_square_sum = dif_square_sum + pow(dif, 2)\n",
    "dif_square_sum = dif_square_sum / len(test_data_small)\n",
    "print(math.sqrt(dif_square_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
